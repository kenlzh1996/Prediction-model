{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c2a24e3",
   "metadata": {},
   "source": [
    "### Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c17f9-bca3-44e5-b665-942a8cc73975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import re\n",
    "import os\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from numpy.random import MT19937\n",
    "from numpy.random import RandomState, SeedSequence\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "from pdb import set_trace\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cfb7cc",
   "metadata": {},
   "source": [
    "### Set seed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688d65a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    rs = RandomState(MT19937(SeedSequence(seed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe99db0",
   "metadata": {},
   "source": [
    "### File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45501b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "raw_data_path = '/home/ec2-user/MLNotebook shared/Datasets/Test set raw data/' # for Johansson and Mertins raw data, \n",
    "dataset_folder_path = '/home/ec2-user/MLNotebook shared/Datasets/' # for localization label\n",
    "output_path = '/home/ec2-user/MLNotebook shared/Datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a64a4",
   "metadata": {},
   "source": [
    "### Preparing data for Krug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b3d82b",
   "metadata": {},
   "source": [
    "#### Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aafbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the labels data\n",
    "LFP = 'SubCellBarcode.MCF7.txt'\n",
    "LD = pd.read_csv(filepath_or_buffer=dataset_folder_path+LFP,sep='\\t')\n",
    "\n",
    "# Data set wrangling\n",
    "LD.index = LD.loc[:,'Protein']\n",
    "LD = LD.loc[:,LD.columns!='Protein']\n",
    "\n",
    "# Remove unclassified class\n",
    "NotUnclassInd = LD.loc[:,'Localization'] != 'Unclassified'\n",
    "LD = LD.loc[NotUnclassInd,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the proteomics data and only keep genes (rows) that are fully quantified\n",
    "PFP = 'kr_pro_raw.csv' # proteomics file path, normalized by pool, log2 transformed.\n",
    "PD = pd.read_csv(dataset_folder_path+PFP)\n",
    "\n",
    "# Data set wrangling\n",
    "PD.index = PD.loc[:,'Gene']\n",
    "PD = PD.loc[:,PD.columns!='Gene']\n",
    "PD.dropna(inplace=True)\n",
    "\n",
    "# Specific for krug raw ddamsproteomics, these 3 tumors are not in transcriptome data\n",
    "PD = PD.loc[:,PD.columns!='X11BR057']\n",
    "PD = PD.loc[:,PD.columns!='X11BR076']\n",
    "PD = PD.loc[:,PD.columns!='X11BR078']\n",
    "\n",
    "# Open the mRNA data and only keep genes (rows) that are fully quantified\n",
    "MFP = 'kr_rna_raw.csv' # mRNA file path, gene centric median normalized, log2 transformed\n",
    "MD = pd.read_csv(dataset_folder_path+MFP)\n",
    "\n",
    "# Data set wrangling\n",
    "MD.index = MD.loc[:,'Gene']\n",
    "MD = MD.loc[:,MD.columns!='Gene']\n",
    "MD = MD.drop_duplicates()\n",
    "MD.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20465a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only genes (rows) are presented in proteome, mRNA and localization data sets\n",
    "IntersectingGenes = [value for value in PD.index if ((value in MD.index) & (value in LD.index))]\n",
    "PD = PD.loc[IntersectingGenes,:]\n",
    "MD = MD.loc[IntersectingGenes,:]\n",
    "LD = LD.loc[IntersectingGenes,:]\n",
    "\n",
    "# Sanity check for the number of genes in each dataframe\n",
    "print('Krug')\n",
    "print(len(PD.index))\n",
    "print(len(MD.index))\n",
    "print(len(LD.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe07cd5",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-log2 transform the proteomics data\n",
    "PD = 2**PD\n",
    "\n",
    "# Normalize by gene average\n",
    "PD = PD.div(PD.mean(axis=1), axis=0)\n",
    "\n",
    "# Normalize by tumor median\n",
    "PD = PD.div(PD.median(axis=0), axis=1)\n",
    "\n",
    "# Log2 transform\n",
    "PD = np.log2(PD)\n",
    "\n",
    "# Standardize by dividing gene standard deviation\n",
    "PD = PD.div(PD.std(axis=1), axis=0)\n",
    "\n",
    "# Put values of each column in the DataFrame into a list\n",
    "values = np.sort(PD.values.flatten().tolist())\n",
    "\n",
    "# Find the 2.5 and 97.5 percentile\n",
    "percentile_high = np.percentile(values, 97.5)\n",
    "percentile_low = np.percentile(values, 2.5)\n",
    "\n",
    "# Use the percentile for normalization\n",
    "PD = (PD) / (percentile_high - percentile_low)\n",
    "\n",
    "# Un-log2 transform the mRNA data\n",
    "MD = 2**MD\n",
    "\n",
    "# Normalize by gene average\n",
    "MD = MD.div(MD.mean(axis=1), axis=0)\n",
    "\n",
    "# Normalize by tumor median\n",
    "MD = MD.div(MD.median(axis=0), axis=1)\n",
    "\n",
    "# Log2 transform\n",
    "MD = np.log2(MD)\n",
    "\n",
    "# Standardize by gene standard deviation\n",
    "MD = MD.div(MD.std(axis=1), axis=0)\n",
    "\n",
    "# Put values of each column in the DataFrame into a list\n",
    "values = np.sort(MD.values.flatten().tolist())\n",
    "\n",
    "# Find the 2.5 and 97.5 percentile\n",
    "percentile_high = np.percentile(values, 97.5)\n",
    "percentile_low = np.percentile(values, 2.5)\n",
    "\n",
    "# Use the percentile for normalization\n",
    "MD = (MD) / (percentile_high - percentile_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb4fd6",
   "metadata": {},
   "source": [
    "### Preparing data for Johansson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72a402",
   "metadata": {},
   "source": [
    "#### Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343305ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the localization data\n",
    "LFP = 'SubCellBarcode.MCF7.txt'\n",
    "LD = pd.read_csv(filepath_or_buffer=raw_data_path+LFP,sep='\\t')\n",
    "\n",
    "# Data set wrangling\n",
    "LD.index = LD.loc[:,'Protein']\n",
    "LD = LD.loc[:,LD.columns!='Protein']\n",
    "\n",
    "# Remove unclassified class\n",
    "NotUnclassInd = LD.loc[:,'Localization'] != 'Unclassified'\n",
    "LD = LD.loc[NotUnclassInd,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Johansson data set\n",
    "# Open the proteomics data and only keep genes (rows) that are fully quantified\n",
    "J_PFP = 'jo_protein_log2.csv' # proteomics file path, normalized by pool, log2 transformed.\n",
    "J_PD = pd.read_csv(raw_data_path+J_PFP)\n",
    "\n",
    "# Data set wrangling\n",
    "J_PD.index = J_PD.loc[:,'Unnamed: 0']\n",
    "J_PD = J_PD.loc[:,J_PD.columns!='Unnamed: 0']\n",
    "J_PD.dropna(inplace=True)\n",
    "\n",
    "# Open the mRNA data and only keep genes (rows) that are fully quantified\n",
    "J_MFP = 'jo_mrna_dropna.csv' # mRNA file path, gene centric median normalized, log2 transformed\n",
    "J_MD = pd.read_csv(raw_data_path + J_MFP)\n",
    "\n",
    "# Data set wrangling\n",
    "J_MD.index = J_MD.loc[:,'Unnamed: 0']\n",
    "J_MD = J_MD.loc[:,J_MD.columns!='Unnamed: 0']\n",
    "J_MD = J_MD.drop_duplicates()\n",
    "J_MD.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbca211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johansson\n",
      "7989\n",
      "7989\n",
      "7989\n"
     ]
    }
   ],
   "source": [
    "# Keep only genes (rows) are presented in proteome, mRNA and localization data sets\n",
    "IntersectingGenes = [value for value in J_PD.index if ((value in J_MD.index) & (value in LD.index))]\n",
    "J_PD = J_PD.loc[IntersectingGenes,:]\n",
    "J_MD = J_MD.loc[IntersectingGenes,:]\n",
    "LD = LD.loc[IntersectingGenes,:]\n",
    "\n",
    "# Sanity check for the number of genes in each dataframe\n",
    "print('Johansson')\n",
    "print(len(J_PD.index))\n",
    "print(len(J_MD.index))\n",
    "print(len(LD.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb1f83",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "303509c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-log2 transform the proteomics data\n",
    "J_PD = 2**J_PD\n",
    "\n",
    "# Normalize by gene average\n",
    "J_PD = J_PD.div(J_PD.mean(axis=1), axis=0)\n",
    "\n",
    "# Normalize by tumor median\n",
    "J_PD = J_PD.div(J_PD.median(axis=0), axis=1)\n",
    "\n",
    "# Log2 transform\n",
    "J_PD = np.log2(J_PD)\n",
    "\n",
    "# Standardize by gene standard deviation\n",
    "J_PD = J_PD.div(J_PD.std(axis=1), axis=0)\n",
    "\n",
    "# Put values of each column in the DataFrame into a list\n",
    "values = np.sort(J_PD.values.flatten().tolist())\n",
    "\n",
    "# Find the 2.5 and 97.5 percentile\n",
    "percentile_high = np.percentile(values, 97.5)\n",
    "percentile_low = np.percentile(values, 2.5)\n",
    "\n",
    "# Use the percentile for normalization\n",
    "J_PD = (J_PD) / (percentile_high - percentile_low)\n",
    "\n",
    "# Un-log2 transform the mRNA data\n",
    "J_MD = 2**J_MD\n",
    "\n",
    "# Normalize by the average of each gene\n",
    "J_MD = J_MD.div(J_MD.mean(axis=1), axis=0)\n",
    "\n",
    "# Normalize by the median of each tumor\n",
    "J_MD = J_MD.div(J_MD.median(axis=0), axis=1)\n",
    "\n",
    "# Log2 transform\n",
    "J_MD = np.log2(J_MD)\n",
    "\n",
    "# Standardize by gene standard deviation\n",
    "J_MD = J_MD.div(J_MD.std(axis=1), axis=0)\n",
    "\n",
    "# Put values of each column in the DataFrame into a list\n",
    "values = np.sort(J_MD.values.flatten().tolist())\n",
    "\n",
    "# Find the 2.5 and 97.5 percentile\n",
    "percentile_high = np.percentile(values, 97.5)\n",
    "percentile_low = np.percentile(values, 2.5)\n",
    "\n",
    "# Use the percentile for normalization\n",
    "J_MD = (J_MD) / (percentile_high - percentile_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e622a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the labels for use\n",
    "LD.to_csv(Path(output_path+'Johansson_Localization.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed5bdf",
   "metadata": {},
   "source": [
    "### Preparing data for Mertins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa2bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the localization data\n",
    "LFP = 'SubCellBarcode.MCF7.txt'\n",
    "LD = pd.read_csv(filepath_or_buffer=raw_data_path+LFP,sep='\\t')\n",
    "\n",
    "# Data set wrangling\n",
    "LD.index = LD.loc[:,'Protein']\n",
    "LD = LD.loc[:,LD.columns!='Protein']\n",
    "\n",
    "# Remove unclassified class\n",
    "NotUnclassInd = LD.loc[:,'Localization'] != 'Unclassified'\n",
    "LD = LD.loc[NotUnclassInd,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mertins data set\n",
    "# Open the proteomics data and only keep genes (rows) that are fully quantified\n",
    "M_PFP = 'me_protein_dropna.csv' # proteomics file path, normalized by pool, log2 transformed.\n",
    "M_PD = pd.read_csv(raw_data_path+M_PFP)\n",
    "\n",
    "# Data set wrangling\n",
    "M_PD.index = M_PD.loc[:,'Unnamed: 0']\n",
    "M_PD = M_PD.loc[:,M_PD.columns!='Unnamed: 0']\n",
    "M_PD.dropna(inplace=True)\n",
    "\n",
    "# Open the mRNA data and only keep genes (rows) that are fully quantified\n",
    "M_MFP = 'me_rna_dropna.csv' # mRNA file path, gene centric median normalized, log2 transformed\n",
    "M_MD = pd.read_csv(raw_data_path + M_MFP)\n",
    "\n",
    "# Data set wrangling\n",
    "M_MD.index = M_MD.loc[:,'Unnamed: 0']\n",
    "M_MD = M_MD.loc[:,M_MD.columns!='Unnamed: 0']\n",
    "M_MD = M_MD.drop_duplicates()\n",
    "M_MD.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only genes (rows) are presented in proteome, mRNA and localization data sets\n",
    "IntersectingGenes = [value for value in M_PD.index if ((value in M_MD.index) & (value in LD.index))]\n",
    "M_PD = M_PD.loc[IntersectingGenes,:]\n",
    "M_MD = M_MD.loc[IntersectingGenes,:]\n",
    "LD = LD.loc[IntersectingGenes,:]\n",
    "\n",
    "# Sanity check for the number of genes in each dataframe\n",
    "print('Mertin')\n",
    "print(len(M_PD.index))\n",
    "print(len(M_MD.index))\n",
    "print(len(LD.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b6eab",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80931f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-log2 transform the proteomics data\n",
    "M_PD = 2**M_PD\n",
    "\n",
    "# Normalize by gene average\n",
    "M_PD = M_PD.div(M_PD.mean(axis=1), axis=0)\n",
    "\n",
    "# Normalize by tumor median\n",
    "M_PD = M_PD.div(M_PD.median(axis=0), axis=1)\n",
    "\n",
    "# Log2 transform\n",
    "M_PD = np.log2(M_PD)\n",
    "\n",
    "# Standardize by gene standard deviation\n",
    "M_PD = M_PD.div(M_PD.std(axis=1), axis=0)\n",
    "\n",
    "# Put values of each column in the DataFrame into a list\n",
    "values = np.sort(M_PD.values.flatten().tolist())\n",
    "\n",
    "# Find the 2.5 and 97.5 percentile\n",
    "percentile_high = np.percentile(values, 97.5)\n",
    "percentile_low = np.percentile(values, 2.5)\n",
    "\n",
    "# Use the percentile for normalization\n",
    "M_PD = (M_PD) / (percentile_high - percentile_low)\n",
    "\n",
    "# Un-log2 transform the mRNA data\n",
    "M_MD = 2**M_MD\n",
    "\n",
    "# Normalize the mRNA data, first divide by the average of each gene\n",
    "M_MD = M_MD.div(M_MD.mean(axis=1), axis=0)\n",
    "\n",
    "# Divide by the median of each column\n",
    "M_MD = M_MD.div(M_MD.median(axis=0), axis=1)\n",
    "\n",
    "# Log2 transform\n",
    "M_MD = np.log2(M_MD)\n",
    "\n",
    "# Standardize by gene standard deviation\n",
    "M_MD = M_MD.div(M_MD.std(axis=1), axis=0)\n",
    "\n",
    "# Put values of each column in the DataFrame into a list\n",
    "values = np.sort(M_MD.values.flatten().tolist())\n",
    "\n",
    "# Find the 2.5 and 97.5 percentile\n",
    "percentile_high = np.percentile(values, 97.5)\n",
    "percentile_low = np.percentile(values, 2.5)\n",
    "\n",
    "# Use the percentile for normalization\n",
    "M_MD = (M_MD) / (percentile_high - percentile_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce36883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the labels for use\n",
    "LD.to_csv(Path(output_path+'Mertins_Localization.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bac864",
   "metadata": {},
   "source": [
    "### Bayesian inference to generate synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d1913a",
   "metadata": {},
   "source": [
    "#### Specify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dbd95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Set = 'Protein + mRNA' # Change it to 'Protein' if only generating proteome synthetic data\n",
    "Bayesian = True\n",
    "Canvas_Size = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa6400",
   "metadata": {},
   "source": [
    "#### Johansson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2090d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51063"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfbc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Johansson Bayesian inference\n",
    "# Ensure reproducibility\n",
    "set_seed(43)\n",
    "\n",
    "if Bayesian:\n",
    "\n",
    "    if Set == 'Protein' or Set == 'Protein + mRNA':\n",
    "        # Fit the dataset to Bayesian Gaussian Mixture Model\n",
    "        PD_bgm = BayesianGaussianMixture(n_components=10, random_state=45) # Assuming the maximum number of clusters in dataset is 5\n",
    "        J_PD_T = J_PD.T\n",
    "        PD_bgm.fit(J_PD_T)\n",
    "    \n",
    "        # Generate X new synthetic tumors, result is an array\n",
    "        if Set == 'Protein':\n",
    "            J_synthetic_PD, _ = PD_bgm.sample(int(Canvas_Size*Canvas_Size-J_PD.columns.size))\n",
    "        elif Set == 'Protein + mRNA':\n",
    "            J_synthetic_PD, _ = PD_bgm.sample(int((Canvas_Size*Canvas_Size-J_PD.columns.size*2)/2))\n",
    "    \n",
    "        # Transpose back before merging\n",
    "        J_synthetic_PD = J_synthetic_PD.T\n",
    "\n",
    "        # Convert the result to a DataFrame\n",
    "        J_synthetic_PD = pd.DataFrame(J_synthetic_PD.tolist(), index=J_PD.index)\n",
    "\n",
    "        # Merge the synthetic data with the original data\n",
    "        J_PD = pd.concat([J_PD, J_synthetic_PD], axis=1)\n",
    "\n",
    "        # Sanity check for the number of tumors in each dataframe\n",
    "        \n",
    "        if Set == 'Protein + mRNA':\n",
    "            assert len(J_PD.columns) == Canvas_Size*Canvas_Size // 2\n",
    "        else:\n",
    "            assert len(J_PD.columns) == Canvas_Size*Canvas_Size\n",
    "\n",
    "        print(f'{Set} - Bayesian Johansson testing PD: {len(J_PD.columns)}')\n",
    "      \n",
    "    if Set == 'mRNA' or Set == 'Protein + mRNA':\n",
    "        # Fit the dataset to Bayesian Gaussian Mixture Model\n",
    "        MD_bgm = BayesianGaussianMixture(n_components=10, random_state=46) # Assuming the maximum number of clusters in dataset is 5\n",
    "        J_MD_T = J_MD.T\n",
    "        MD_bgm.fit(J_MD_T)\n",
    "\n",
    "        # Generate X new synthetic tumors, result is an array\n",
    "        if Set == 'mRNA':\n",
    "            J_synthetic_MD, _ = MD_bgm.sample(int(Canvas_Size*Canvas_Size-J_MD.columns.size))\n",
    "        if Set == 'Protein + mRNA':\n",
    "            J_synthetic_MD, _ = MD_bgm.sample(int((Canvas_Size*Canvas_Size-J_MD.columns.size*2)/2))\n",
    "\n",
    "        # Transpose back before merging\n",
    "        J_synthetic_MD = J_synthetic_MD.T\n",
    "\n",
    "        # Convert the result to a DataFrame\n",
    "        J_synthetic_MD = pd.DataFrame(J_synthetic_MD.tolist(), index=J_MD.index)\n",
    "\n",
    "        # Merge the synthetic data with the original data\n",
    "        J_MD = pd.concat([J_MD, J_synthetic_MD], axis=1)\n",
    "         \n",
    "        # Sanity check for the number of tumors in each dataframe\n",
    "        if Set == 'Protein + mRNA':\n",
    "            assert len(J_MD.columns) == Canvas_Size*Canvas_Size // 2\n",
    "        else:\n",
    "            assert len(J_MD.columns) == Canvas_Size*Canvas_Size\n",
    "        print(f'{Set} - Bayesian Johansson testing MD: {len(J_MD.columns)}')\n",
    "\n",
    "else:\n",
    "    print('No synthetic data generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2182046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the synthetic data\n",
    "if Set == 'Protein + mRNA':\n",
    "    J_PD.to_csv(Path(output_path + 'J_prot+mRNA_PD_synthetic_new.csv'))\n",
    "    J_MD.to_csv(Path(output_path + 'J_prot+mRNA_MD_synthetic_new.csv'))\n",
    "elif Set == 'Protein':\n",
    "    J_PD.to_csv(Path(output_path + 'J_prot_PD_synthetic_new.csv'))\n",
    "elif Set == 'mRNA':\n",
    "    J_MD.to_csv(Path(output_path + 'J_mRNA_MD_synthetic_new.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeded15",
   "metadata": {},
   "source": [
    "#### Mertins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3580a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb994107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mertins Bayesian inference\n",
    "set_seed(43)\n",
    "\n",
    "if Bayesian:\n",
    "\n",
    "    if Set == 'Protein' or Set == 'Protein + mRNA':\n",
    "        # Fit the dataset to Bayesian Gaussian Mixture Model\n",
    "        PD_bgm = BayesianGaussianMixture(n_components=15, random_state=47) # Assuming the maximum number of clusters in dataset is 5\n",
    "        M_PD_T = M_PD.T\n",
    "        PD_bgm.fit(M_PD_T)\n",
    "    \n",
    "        # Generate X new synthetic tumors, result is an array\n",
    "        if Set == 'Protein':\n",
    "            M_synthetic_PD, _ = PD_bgm.sample(int(Canvas_Size*Canvas_Size-M_PD.columns.size))\n",
    "        elif Set == 'Protein + mRNA':\n",
    "            M_synthetic_PD, _ = PD_bgm.sample(int((Canvas_Size*Canvas_Size-M_PD.columns.size*2)/2))\n",
    "    \n",
    "        # Transpose back before merging\n",
    "        M_synthetic_PD = M_synthetic_PD.T\n",
    "\n",
    "        # Convert the result to a DataFrame\n",
    "        M_synthetic_PD = pd.DataFrame(M_synthetic_PD.tolist(), index=M_PD.index)\n",
    "\n",
    "        # Merge the synthetic data with the original data\n",
    "        M_PD = pd.concat([M_PD, M_synthetic_PD], axis=1)\n",
    "\n",
    "        # Sanity check for the number of tumors in each dataframe\n",
    "        \n",
    "        if Set == 'Protein + mRNA':\n",
    "            assert len(M_PD.columns) == Canvas_Size*Canvas_Size // 2\n",
    "        else:\n",
    "            assert len(M_PD.columns) == Canvas_Size*Canvas_Size\n",
    "\n",
    "        print(f'{Set} - Bayesian Mertin testing PD: {len(M_PD.columns)}')\n",
    "      \n",
    "    if Set == 'mRNA' or Set == 'Protein + mRNA':\n",
    "        # Fit the dataset to Bayesian Gaussian Mixture Model\n",
    "        MD_bgm = BayesianGaussianMixture(n_components=15, random_state=48) # Assuming the maximum number of clusters in dataset is 5\n",
    "        M_MD_T = M_MD.T\n",
    "        MD_bgm.fit(M_MD_T)\n",
    "\n",
    "        # Generate X new synthetic tumors, result is an array\n",
    "        if Set == 'mRNA':\n",
    "            M_synthetic_MD, _ = MD_bgm.sample(int(Canvas_Size*Canvas_Size-M_MD.columns.size))\n",
    "        if Set == 'Protein + mRNA':\n",
    "            M_synthetic_MD, _ = MD_bgm.sample(int((Canvas_Size*Canvas_Size-M_MD.columns.size*2)/2))\n",
    "\n",
    "        # Transpose back before merging\n",
    "        M_synthetic_MD = M_synthetic_MD.T\n",
    "\n",
    "        # Convert the result to a DataFrame\n",
    "        M_synthetic_MD = pd.DataFrame(M_synthetic_MD.tolist(), index=M_MD.index)\n",
    "\n",
    "        # Merge the synthetic data with the original data\n",
    "        M_MD = pd.concat([M_MD, M_synthetic_MD], axis=1)\n",
    "         \n",
    "        # Sanity check for the number of tumors in each dataframe\n",
    "        if Set == 'Protein + mRNA':\n",
    "            assert len(M_MD.columns) == Canvas_Size*Canvas_Size // 2\n",
    "        else:\n",
    "            assert len(M_MD.columns) == Canvas_Size*Canvas_Size\n",
    "        print(f'{Set} - Bayesian Mertin testing MD: {len(M_MD.columns)}')\n",
    "\n",
    "else:\n",
    "    print('No synthetic data generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2de3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "if Set == 'Protein + mRNA':\n",
    "    M_PD.to_csv(Path(output_path + 'M_prot+mRNA_PD_synthetic_new.csv'))\n",
    "    M_MD.to_csv(Path(output_path + 'M_prot+mRNA_MD_synthetic_new.csv'))\n",
    "elif Set == 'Protein':\n",
    "    M_PD.to_csv(Path(output_path + 'M_prot_PD_synthetic_new.csv'))\n",
    "elif Set == 'mRNA':\n",
    "    M_MD.to_csv(Path(output_path + 'M_mRNA_MD_synthetic_new.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86875c9e",
   "metadata": {},
   "source": [
    "#### Krug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f302582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed to ensure reproducibility\n",
    "set_seed(43)\n",
    "\n",
    "if Bayesian:\n",
    "\n",
    "    if Set == 'Protein' or Set == 'Protein + mRNA':\n",
    "        # Fit the dataset to Bayesian Gaussian Mixture Model\n",
    "        PD_bgm = BayesianGaussianMixture(n_components=15, random_state=42) # Assuming the maximum number of clusters in dataset is 5\n",
    "        PD_T = PD.T\n",
    "        PD_bgm.fit(PD_T)\n",
    "    \n",
    "        # Generate X new synthetic tumors, result is an array\n",
    "        if Set == 'Protein':\n",
    "            synthetic_PD, _ = PD_bgm.sample(int(Canvas_Size*Canvas_Size-PD.columns.size))\n",
    "        elif Set == 'Protein + mRNA':\n",
    "            synthetic_PD, _ = PD_bgm.sample(int((Canvas_Size*Canvas_Size-PD.columns.size*2)/2))\n",
    "    \n",
    "        # Transpose back before merging\n",
    "        synthetic_PD = synthetic_PD.T\n",
    "\n",
    "        # Convert the result to a DataFrame\n",
    "        synthetic_PD = pd.DataFrame(synthetic_PD.tolist(), index=PD.index)\n",
    "\n",
    "        # Merge the synthetic data with the original data\n",
    "        PD = pd.concat([PD, synthetic_PD], axis=1)\n",
    "\n",
    "        # Sanity check for the number of tumors in each dataframe\n",
    "        \n",
    "        if Set == 'Protein + mRNA':\n",
    "            assert len(PD.columns) == Canvas_Size*Canvas_Size // 2\n",
    "        else:\n",
    "            assert len(PD.columns) == Canvas_Size*Canvas_Size\n",
    "\n",
    "        print(f'{Set} - Bayesian PD: {len(PD.columns)}')\n",
    "      \n",
    "    if Set == 'mRNA' or Set == 'Protein + mRNA':\n",
    "        # Fit the dataset to Bayesian Gaussian Mixture Model\n",
    "        MD_bgm = BayesianGaussianMixture(n_components=15, random_state=43) # Assuming the maximum number of clusters in dataset is 5\n",
    "        MD_T = MD.T\n",
    "        MD_bgm.fit(MD_T)\n",
    "\n",
    "        # Generate X new synthetic tumors, result is an array\n",
    "        if Set == 'mRNA':\n",
    "            synthetic_MD, _ = MD_bgm.sample(int(Canvas_Size*Canvas_Size-MD.columns.size))\n",
    "        elif Set == 'Protein + mRNA':\n",
    "            synthetic_MD, _ = MD_bgm.sample(int((Canvas_Size*Canvas_Size-MD.columns.size*2)/2))\n",
    "\n",
    "        # Transpose back before merging\n",
    "        synthetic_MD = synthetic_MD.T\n",
    "\n",
    "        # Convert the result to a DataFrame\n",
    "        synthetic_MD = pd.DataFrame(synthetic_MD.tolist(), index=MD.index)\n",
    "\n",
    "        # Merge the synthetic data with the original data\n",
    "        MD = pd.concat([MD, synthetic_MD], axis=1)\n",
    "         \n",
    "        # Sanity check for the number of tumors in each dataframe\n",
    "        if Set == 'Protein + mRNA':\n",
    "            assert len(MD.columns) == Canvas_Size*Canvas_Size // 2\n",
    "        else:\n",
    "            assert len(MD.columns) == Canvas_Size*Canvas_Size\n",
    "        print(f'{Set} - Bayesian MD: {len(MD.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9effa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "if Set == 'Protein + mRNA':\n",
    "    PD.to_csv(Path(output_path + 'K_prot+mRNA_PD_synthetic_after.csv'))\n",
    "    MD.to_csv(Path(output_path + 'K_prot+mRNA_MD_synthetic_after.csv'))\n",
    "elif Set == 'Protein':\n",
    "    PD.to_csv(Path(output_path + 'K_prot_PD_synthetic_after.csv'))\n",
    "elif Set == 'mRNA':\n",
    "    MD.to_csv(Path(output_path + 'K_mRNA_MD_synthetic_after.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
